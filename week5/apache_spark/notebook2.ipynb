{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "import pyspark.sql.functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"FirstApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the schema for your DataFrame\n",
    "\n",
    "myschema = StructType([\n",
    "    StructField(\"userID\",IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"friends\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe on a csv file\n",
    "people = spark.read.csv(\"fakefriends.csv\",schema=myschema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing the transformations\n",
    "output = people.select(people.userID, people.name, people.age,people.friends)\\\n",
    "               .where(people.age < 30).withColumn('insert_ts', func.current_timestamp())\\\n",
    "               .orderBy(people.userID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---+-------+--------------------+\n",
      "|userID|    name|age|friends|           insert_ts|\n",
      "+------+--------+---+-------+--------------------+\n",
      "|     1|Jean-Luc| 26|      2|2025-04-04 17:30:...|\n",
      "|     9|    Hugh| 27|    181|2025-04-04 17:30:...|\n",
      "|    16|  Weyoun| 22|    323|2025-04-04 17:30:...|\n",
      "|    21|   Miles| 19|    268|2025-04-04 17:30:...|\n",
      "|    24|  Julian| 25|      1|2025-04-04 17:30:...|\n",
      "|    25|     Ben| 21|    445|2025-04-04 17:30:...|\n",
      "|    26|  Julian| 22|    100|2025-04-04 17:30:...|\n",
      "|    32|     Nog| 26|    281|2025-04-04 17:30:...|\n",
      "|    35| Beverly| 27|    305|2025-04-04 17:30:...|\n",
      "|    46|    Morn| 25|     96|2025-04-04 17:30:...|\n",
      "|    47|   Brunt| 24|     49|2025-04-04 17:30:...|\n",
      "|    48|     Nog| 20|      1|2025-04-04 17:30:...|\n",
      "|    52| Beverly| 19|    269|2025-04-04 17:30:...|\n",
      "|    54|   Brunt| 19|      5|2025-04-04 17:30:...|\n",
      "|    60|  Geordi| 20|    100|2025-04-04 17:30:...|\n",
      "|    66|  Geordi| 21|    477|2025-04-04 17:30:...|\n",
      "|    72|  Kasidy| 22|    179|2025-04-04 17:30:...|\n",
      "|    73|   Brunt| 20|    384|2025-04-04 17:30:...|\n",
      "|    84|     Ben| 28|    311|2025-04-04 17:30:...|\n",
      "|    89|    Worf| 24|    492|2025-04-04 17:30:...|\n",
      "+------+--------+---+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a temporary view\n",
    "output.createOrReplaceTempView(\"peoples\")\n",
    "spark.sql(\"select name,age,friends,insert_ts from peoples\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating another temporary view\n",
    "people.createOrReplaceTempView(\"people_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.createOrReplaceTempView(\"peoples\")  # Ensure insert_ts is included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "peoples = output.createOrReplaceTempView(\"peoples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msqlQuery\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Returns a :class:`DataFrame` representing the result of the given query.\n",
      "When ``kwargs`` is specified, this method formats the given string by using the Python\n",
      "standard formatter. The method binds named parameters to SQL literals or\n",
      "positional parameters from `args`. It doesn't support named and positional parameters\n",
      "in the same SQL query.\n",
      "\n",
      ".. versionadded:: 2.0.0\n",
      "\n",
      ".. versionchanged:: 3.4.0\n",
      "    Supports Spark Connect and parameterized SQL.\n",
      "\n",
      ".. versionchanged:: 3.5.0\n",
      "    Added positional parameters.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "sqlQuery : str\n",
      "    SQL query string.\n",
      "args : dict or list\n",
      "    A dictionary of parameter names to Python objects or a list of Python objects\n",
      "    that can be converted to SQL literal expressions. See\n",
      "    <a href=\"https://spark.apache.org/docs/latest/sql-ref-datatypes.html\">\n",
      "    Supported Data Types</a> for supported value types in Python.\n",
      "    For example, dictionary keys: \"rank\", \"name\", \"birthdate\";\n",
      "    dictionary or list values: 1, \"Steven\", datetime.date(2023, 4, 2).\n",
      "    A value can be also a `Column` of literal expression, in that case it is taken as is.\n",
      "\n",
      "    .. versionadded:: 3.4.0\n",
      "\n",
      "kwargs : dict\n",
      "    Other variables that the user wants to set that can be referenced in the query\n",
      "\n",
      "    .. versionchanged:: 3.3.0\n",
      "       Added optional argument ``kwargs`` to specify the mapping of variables in the query.\n",
      "       This feature is experimental and unstable.\n",
      "\n",
      "Returns\n",
      "-------\n",
      ":class:`DataFrame`\n",
      "\n",
      "Examples\n",
      "--------\n",
      "Executing a SQL query.\n",
      "\n",
      ">>> spark.sql(\"SELECT * FROM range(10) where id > 7\").show()\n",
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "\n",
      "Executing a SQL query with variables as Python formatter standard.\n",
      "\n",
      ">>> spark.sql(\n",
      "...     \"SELECT * FROM range(10) WHERE id > {bound1} AND id < {bound2}\", bound1=7, bound2=9\n",
      "... ).show()\n",
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  8|\n",
      "+---+\n",
      "\n",
      ">>> mydf = spark.range(10)\n",
      ">>> spark.sql(\n",
      "...     \"SELECT {col} FROM {mydf} WHERE id IN {x}\",\n",
      "...     col=mydf.id, mydf=mydf, x=tuple(range(4))).show()\n",
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "+---+\n",
      "\n",
      ">>> spark.sql('''\n",
      "...   SELECT m1.a, m2.b\n",
      "...   FROM {table1} m1 INNER JOIN {table2} m2\n",
      "...   ON m1.key = m2.key\n",
      "...   ORDER BY m1.a, m2.b''',\n",
      "...   table1=spark.createDataFrame([(1, \"a\"), (2, \"b\")], [\"a\", \"key\"]),\n",
      "...   table2=spark.createDataFrame([(3, \"a\"), (4, \"b\"), (5, \"b\")], [\"b\", \"key\"])).show()\n",
      "+---+---+\n",
      "|  a|  b|\n",
      "+---+---+\n",
      "|  1|  3|\n",
      "|  2|  4|\n",
      "|  2|  5|\n",
      "+---+---+\n",
      "\n",
      "Also, it is possible to query using class:`Column` from :class:`DataFrame`.\n",
      "\n",
      ">>> mydf = spark.createDataFrame([(1, 4), (2, 4), (3, 6)], [\"A\", \"B\"])\n",
      ">>> spark.sql(\"SELECT {df.A}, {df[B]} FROM {df}\", df=mydf).show()\n",
      "+---+---+\n",
      "|  A|  B|\n",
      "+---+---+\n",
      "|  1|  4|\n",
      "|  2|  4|\n",
      "|  3|  6|\n",
      "+---+---+\n",
      "\n",
      "And substitude named parameters with the `:` prefix by SQL literals.\n",
      "\n",
      ">>> spark.sql(\"SELECT * FROM {df} WHERE {df[B]} > :minB\", {\"minB\" : 5}, df=mydf).show()\n",
      "+---+---+\n",
      "|  A|  B|\n",
      "+---+---+\n",
      "|  3|  6|\n",
      "+---+---+\n",
      "\n",
      "Or positional parameters marked by `?` in the SQL query by SQL literals.\n",
      "\n",
      ">>> spark.sql(\n",
      "...   \"SELECT * FROM {df} WHERE {df[B]} > ? and ? < {df[A]}\",\n",
      "...   args=[5, 2], df=mydf).show()\n",
      "+---+---+\n",
      "|  A|  B|\n",
      "+---+---+\n",
      "|  3|  6|\n",
      "+---+---+\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\blais\\documents\\data_engineering\\venv\\lib\\site-packages\\pyspark\\sql\\session.py\n",
      "\u001b[1;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "spark.sql?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = spark.range(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mydf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o126.namespace. Trace:\npy4j.Py4JException: Method namespace([]) does not exist\r\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\r\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\r\n\tat py4j.Gateway.invoke(Gateway.java:274)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistTables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\blais\\Documents\\data_engineering\\venv\\Lib\\site-packages\\pyspark\\sql\\catalog.py:368\u001b[0m, in \u001b[0;36mCatalog.listTables\u001b[1;34m(self, dbName, pattern)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28miter\u001b[39m\u001b[38;5;241m.\u001b[39mhasNext():\n\u001b[0;32m    366\u001b[0m     jtable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m\u001b[38;5;241m.\u001b[39mnext()\n\u001b[1;32m--> 368\u001b[0m     jnamespace \u001b[38;5;241m=\u001b[39m \u001b[43mjtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m jnamespace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m         namespace \u001b[38;5;241m=\u001b[39m [jnamespace[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(jnamespace))]\n",
      "File \u001b[1;32mc:\\Users\\blais\\Documents\\data_engineering\\venv\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\blais\\Documents\\data_engineering\\venv\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\blais\\Documents\\data_engineering\\venv\\Lib\\site-packages\\py4j\\protocol.py:330\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n",
      "\u001b[1;31mPy4JError\u001b[0m: An error occurred while calling o126.namespace. Trace:\npy4j.Py4JException: Method namespace([]) does not exist\r\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\r\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\r\n\tat py4j.Gateway.invoke(Gateway.java:274)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n\n"
     ]
    }
   ],
   "source": [
    "print(spark.catalog.listTables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
